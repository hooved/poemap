{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3f04e-191c-436c-9959-be64346b7d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, importlib, sys\n",
    "from collections import defaultdict\n",
    "from stream.client import draw_minimap, frames_to_map\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e5677-3b2b-4f84-a74d-84526ce65c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "manually captured frames of coast map in 4k\n",
    "- the frames are grouped by key, where each key represents a separate instance of the layout\n",
    "- first frame of a group is always centered at map entrance, we track origin position based on this first frame\n",
    "- the frame groups are further grouped by layout ID, which was assigned by human inspection as ground truth\n",
    "\n",
    "current approach to train a vision transformer:\n",
    "\n",
    "1. for each set of N frames, assemble N minimaps:\n",
    " {frame 0}, {frame 0 + frame 1}, ..., {frame 0 + .. + frame N}\n",
    " where {frame + frame} represents assembling a composite minimap from minimap slices in these frames\n",
    " \n",
    "2. then extract minimap feature masks, crop to minimize surrounding blank space\n",
    "\n",
    "3. each minimap mask is an input, output is softmax probabilities for N classes, where N is the number of unique layouts\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b1e14-f157-4efb-b8ec-4f5120197ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 4k screenshots\n",
    "layouts = {}\n",
    "for layout in os.listdir(\"data/train\"):\n",
    "    frames = defaultdict(dict)\n",
    "    data_dir = os.path.join(\"data/train\", layout)\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".png\"):\n",
    "            key = file.split(\"screenshot-\")[0]\n",
    "            full_path = os.path.join(data_dir, file)\n",
    "            number = int(file.split(\"screenshot-\")[1][:-4])\n",
    "            frames[key][number] = np.array(Image.open(full_path))\n",
    "    layouts[int(layout)] = frames\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8545a-61d7-4ace-89d9-61e913d5f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract middle of 4k frame\n",
    "# player icon is at 1920, 1060, in 4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2a51d-792c-49f8-888a-4edb4298fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_radius = 600\n",
    "frames = []\n",
    "for instance in layouts[0]:\n",
    "    frame_ids = sorted(layouts[0][instance].keys())\n",
    "    for frame_id in frame_ids:\n",
    "        print(frame_id)\n",
    "        frames.append(layouts[0][instance][frame_id])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066c451-5e69-490a-a3f5-e85aa417fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd2efe-6e54-46e0-8f49-d29620393d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393103a5-ae44-430e-a5dd-3c434ae44679",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = frames[:, 1060-box_radius: 1060+box_radius, 1920-box_radius: 1920+box_radius, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d0d3e-dd7c-42b4-a437-381a6230bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17564b73-62f3-4b7a-bda0-cc2639af164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cropped.shape[0]):\n",
    "    #display(Image.fromarray(cropped[i]))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b059b8-ce3f-48ca-8b15-5b77c577f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_module = sys.modules['stream.client']\n",
    "importlib.reload(client_module)\n",
    "from stream.client import draw_minimap, frames_to_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8323f-9188-46ed-a5cf-9b3602ac2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch frames together, tracking origin\n",
    "minimap, origin = frames_to_map(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7d997-36d2-4c74-b6c3-757f63de69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d568a3a-5ff4-4636-896a-df247b9bfb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = minimap[origin[0]-100:origin[0]+100, origin[1]-100:origin[1]+100, :]\n",
    "ent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f441c9c-98ba-4496-bc67-36a71eb32b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b5d74-90c6-4d8f-85ee-e9615aeeb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import pad_to_square_multiple, shrink_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770bf24-c9d7-45ac-85da-9ed91e61c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink and pad image\n",
    "\n",
    "#Image.fromarray(minimap)\n",
    "dims = minimap.shape[0:2]\n",
    "max_dim_idx = dims.index(max(dims))\n",
    "new_size = dims[max_dim_idx] // 2\n",
    "shrunk_origin = tuple(int(x * new_size / max(dims)) for x in origin)\n",
    "shrunk = shrink_image(minimap, new_size)\n",
    "# Use mask to track origin position\n",
    "mask = np.zeros((*shrunk.shape[0:2], 1))\n",
    "mask[shrunk_origin] = 1\n",
    "shrunk = np.concatenate([shrunk, mask], axis=-1)\n",
    "padded = pad_to_square_multiple(shrunk, 32)\n",
    "shrunk_origin = np.where(padded[..., 3] == 1)\n",
    "shrunk_origin = tuple(int(x[0]) for x in shrunk_origin)\n",
    "padded = padded[:,:,0:3].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78091481-395d-42c1-b4ea-8428221e5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image.fromarray(padded)\n",
    "#Image.fromarray(padded[shrunk_origin[0]-100:shrunk_origin[0]+100, shrunk_origin[1]-100:shrunk_origin[1]+100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995c622-bbaf-47a4-aff6-1100077b9d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7896c-1778-42de-94fa-741cae0c72d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c29d1c-72f8-4130-9e9b-5ed1f91eede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference to extract mask of minimap features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b5740-01ef-4a19-a9db-5248a21cb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AttentionUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0072474-8382-48d4-a349-a7d65ca82ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"AttentionUNet_4\"\n",
    "model = AttentionUNet(model_name)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf975478-d73a-4ea0-9882-39e3a2d3051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.batch_inference(padded, chunk_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b912f-ad38-4fe7-96ff-ea02c2b58895",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image.fromarray(padded))\n",
    "display(Image.fromarray(pred * 255, mode=\"L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579f147-0394-408a-ba43-0955fcebce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc717b-b544-47ec-8bb0-d88963bbe17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "def crop_to_content(image):\n",
    "    white_pixels = np.argwhere(image == 1)\n",
    "    assert len(white_pixels) > 0\n",
    "    \n",
    "    y_min, x_min = white_pixels.min(axis=0)\n",
    "    y_max, x_max = white_pixels.max(axis=0)\n",
    "    cropped_image = image[y_min:y_max+1, x_min:x_max+1]\n",
    "    return cropped_image, (y_min, x_min)\n",
    "\n",
    "def clean_sparse_pixels(image, threshold=3, neighborhood_size=3):\n",
    "    # Create a kernel for counting neighbors\n",
    "    kernel = np.ones((neighborhood_size, neighborhood_size))\n",
    "    kernel[neighborhood_size//2, neighborhood_size//2] = 0  # Don't count the pixel itself\n",
    "    # Count white neighbors for each pixel\n",
    "    neighbor_count = convolve(image.astype(int), kernel, mode='constant')\n",
    "    # Create a mask of pixels to keep (either black or with enough white neighbors)\n",
    "    mask = (image == 0) | (neighbor_count >= threshold)\n",
    "    # Apply the mask to the original image\n",
    "    cleaned_image = image * mask\n",
    "    \n",
    "    return cleaned_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38cc83-28f3-4593-8bb3-40a5542f5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean_sparse_pixels(pred, threshold=20, neighborhood_size=40)\n",
    "clean, offsets = crop_to_content(clean)\n",
    "display(Image.fromarray(padded))\n",
    "display(Image.fromarray(clean * 255, mode=\"L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe452d-ad7e-4adc-ae96-c23feb879b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_origin = tuple(int(val - offset) for val, offset in zip(shrunk_origin, offsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00625c05-11e3-47ea-a50a-7647f66ff3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = clean_origin\n",
    "Image.fromarray(clean[x-50:x+50, y-50:y+50] * 255, mode=\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf64c8-dcc5-41aa-a734-dacf9e4fa105",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf0224-e32e-429f-a158-bb06ccbc442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001f1a2-232f-4a27-865f-a2c8b7772b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the map into square patches, label each patch with y,x positions relative to origin\n",
    "# We will use the y,x positions for token position embeddings\n",
    "def get_patches(array, origin, ps=32):\n",
    "    assert len(array.shape) == 2\n",
    "    Y, X = array.shape\n",
    "    # calc num patches in each direction from origin\n",
    "    y, x = origin\n",
    "    up, down = y//ps, (Y-y)//ps\n",
    "    left, right = x//ps, (X-x)//ps\n",
    "    patches = array[y-ps*up : y+ps*down, x-ps*left : x+ps*right]\n",
    "\n",
    "    # calc patch y,x dims for each pixel, relative to origin patch\n",
    "    indices = np.indices(patches.shape).transpose(1,2,0)\n",
    "    indices = indices // ps - np.array([up, left])\n",
    "    patches = patches.reshape(*patches.shape, 1)\n",
    "    patches = np.concatenate([patches, indices], axis=-1)\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d48b62-9a32-41cd-801e-bfcc681be3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = get_patches(clean, clean_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72784044-e340-43d3-9d32-c525a7c917ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(patches[:,:,0].astype(np.uint8) * 255, mode=\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7aece-1177-4a3c-87c4-3d41f0158d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove completely black patches\n",
    "def get_tokens(patches):\n",
    "    Y,X = patches.shape[0:2]\n",
    "    y_patches, x_patches = Y // 32, X // 32\n",
    "    tokens = []\n",
    "    for i in range(y_patches):\n",
    "        for j in range(x_patches):\n",
    "            patch = patches[i*32 : (i+1)*32, j*32 : (j+1)*32]\n",
    "            if np.any(patch[:,:,0] > 0):\n",
    "                tokens.append(patch)\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a3b04-5e07-463a-bf72-e9e19a0d51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_tokens(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808249c-c078-41e8-9390-f45b9d30fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea39038c-1fce-48e4-9945-2164a27ec5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in tokens:\n",
    "    #display(Image.fromarray(p[:,:,0].astype(np.uint8) * 255, mode=\"L\"))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d490f8d-ec92-4d35-ae00-37afa7986698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8830e4-c9e5-44e1-94fc-6bc0f2a57e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 256\n",
    "assert dim % 4 == 0\n",
    "num_tokens = tokens.shape[0]\n",
    "x_coords = tokens[:,0,0,1].reshape(tokens.shape[0], 1)\n",
    "y_coords = tokens[:,0,0,2].reshape(tokens.shape[0], 1)\n",
    "embeds = np.zeros((num_tokens, dim))\n",
    "denoms = np.exp(np.arange(0, dim, 4) / dim * -np.log(10000.0)).reshape(1, dim // 4)\n",
    "embeds[:, 0::4] = np.sin(x_coords * denoms) \n",
    "embeds[:, 1::4] = np.cos(x_coords * denoms) \n",
    "embeds[:, 2::4] = np.sin(y_coords * denoms) \n",
    "embeds[:, 3::4] = np.cos(y_coords * denoms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae6039-10eb-49ed-8222-79ffed582b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in ('models.vit', 'models'):\n",
    "    client_module = sys.modules[module]\n",
    "    importlib.reload(client_module)\n",
    "from models import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358d0a6-fbe8-41eb-84cf-bb4c01f330df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(9, max_tokens=128, layers=3, embed_dim=256, num_heads=4)\n",
    "#model_name = \"AttentionUNet_1\"\n",
    "#model = ViT(model_name)\n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520a895-22b0-495f-9330-d97337dc812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ddef7-efc0-4df2-993b-077723404060",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model([tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f493d-9d56-4178-91ce-fdfcc0f04a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff1bea-d9c2-42a5-98aa-9d30857d7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f36c3e5-7828-4aa6-b328-2ef75a6b6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poemap",
   "language": "python",
   "name": "poemap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
