{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a6a33-03bb-4bbe-87c9-432aa7dc3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from helpers import pad_to_square_multiple, shrink_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53123d-f1a2-4a76-825d-c6b487d5bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We want to train a model to take any game screenshot and extract only the map features.\n",
    "This is what people do when they look at the screen.\n",
    "\n",
    "To assemble training data, we start by taking a screenshot in game, manually crop the image \n",
    "with MS paint to a smaller area that only contains the map information, with minimal stuff \n",
    "in the background.\n",
    "\n",
    "The blue map lines seem like their colors can be distored by background interference \n",
    "(e.g. fires), which we minimize with this manual crop. Then we can just use color filters to\n",
    "extract the map lines.\n",
    "\n",
    "These extracted map lines are ground truth. The other screenshots in our model training data\n",
    "have the same lines, but overlayed on much noisier backgrounds. The model will learn to \n",
    "convert the noisy screenshots to the clean map features.\n",
    "\"\"\"\n",
    "manual_crop = Image.open(\"data/manual_crop/0.png\")\n",
    "# remove alpha channel added while cropping with ms paint\n",
    "display(manual_crop)\n",
    "manual_crop = np.array(manual_crop)[:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2265db0-37ab-49df-bcd1-aeef062bf78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_color_ranges(image, ranges):\n",
    "    \"\"\"\n",
    "    Filter an image to keep only pixels within specified color ranges.\n",
    "    \n",
    "    :param image: NumPy array of shape (height, width, 3) with values 0-255\n",
    "    :param ranges: List of tuples, each containing min and max values for R, G, and B\n",
    "    :return: Filtered image with pixels outside the ranges set to black\n",
    "    \"\"\"\n",
    "    # Create a copy of the image\n",
    "    filtered_image = image.copy()\n",
    "    \n",
    "    # Create a mask initialized with all False\n",
    "    mask = np.zeros(image.shape[:2], dtype=bool)\n",
    "    \n",
    "    # For each color range, update the mask\n",
    "    for (r_min, r_max), (g_min, g_max), (b_min, b_max) in ranges:\n",
    "        range_mask = (\n",
    "            (image[:,:,0] >= r_min) & (image[:,:,0] <= r_max) &\n",
    "            (image[:,:,1] >= g_min) & (image[:,:,1] <= g_max) &\n",
    "            (image[:,:,2] >= b_min) & (image[:,:,2] <= b_max)\n",
    "        )\n",
    "        mask |= range_mask\n",
    "    \n",
    "    # Apply the mask: set pixels outside the ranges to black\n",
    "    filtered_image[~mask] = [0, 0, 0]\n",
    "    \n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ce54e-d495-4abd-8106-8026b507941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(image):\n",
    "    # Define color ranges: (R_min, R_max), (G_min, G_max), (B_min, B_max)\n",
    "    bluish_range = ((110, 150), (0, 150), (150, 255))\n",
    "    color_ranges = [bluish_range]\n",
    "    map_lines = filter_color_ranges(image, color_ranges)\n",
    "    mask = np.any(map_lines > 0, axis=2).astype(np.uint8)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565fe915-c250-4456-95f6-8b5a5867c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract door subsection which is anchor point for aligning and cropping screenshots\n",
    "\n",
    "def largest_true_subsection(arr):\n",
    "    if not arr.any():\n",
    "        return (0, 0, 0, 0)  # No True values\n",
    "    \n",
    "    rows, cols = arr.shape\n",
    "    heights = np.zeros(cols, dtype=int)\n",
    "    max_area = 0\n",
    "    max_rect = (0, 0, 0, 0)  # (top, left, height, width)\n",
    "\n",
    "    for row in range(rows):\n",
    "        heights = (heights + 1) * arr[row]\n",
    "        stack = [-1]\n",
    "        \n",
    "        for col in range(cols + 1):\n",
    "            h = heights[col] if col < cols else 0\n",
    "            while stack[-1] != -1 and heights[stack[-1]] > h:\n",
    "                height = heights[stack.pop()]\n",
    "                width = col - stack[-1] - 1\n",
    "                area = height * width\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    max_rect = (row - height + 1, stack[-1] + 1, height, width)\n",
    "            stack.append(col)\n",
    "\n",
    "    return max_rect\n",
    "\n",
    "def extract_subsection(arr, subsection):\n",
    "    top, left, height, width = subsection\n",
    "    return arr[top:top+height, left:left+width]\n",
    "    \n",
    "def extract_door_subsection(image):\n",
    "    # Turn all pixels black except door\n",
    "    orangeish_range = ((180, 220), (80, 125), (35, 45))  # More red, some green, little blue\n",
    "    color_ranges = [orangeish_range]\n",
    "    door = filter_color_ranges(image, color_ranges)\n",
    "    # crop the door\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(door, cv2.COLOR_RGB2GRAY)\n",
    "    # Threshold the image to create a binary mask\n",
    "    _, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Find the bounding rectangle of the icon\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "    # Crop the icon\n",
    "    door = door[y:y+h, x:x+w]\n",
    "    mask = np.all(door != 0, axis=-1)\n",
    "    subsection = largest_true_subsection(mask)\n",
    "    return extract_subsection(door, subsection)\n",
    "\n",
    "def auto_crop_ss(ss, manual_crop):\n",
    "    door_subsection = extract_door_subsection(manual_crop)\n",
    "    # Convert RGB to BGR for OpenCV processing\n",
    "    manual_crop_bgr = cv2.cvtColor(manual_crop, cv2.COLOR_RGB2BGR)\n",
    "    door_subsection_bgr = cv2.cvtColor(door_subsection, cv2.COLOR_RGB2BGR)\n",
    "    # Automatically crop the source image to the same size as the manually cropped image,\n",
    "    # with perfect overlap of the door subsection between the two images\n",
    "    image_bgr = cv2.cvtColor(ss, cv2.COLOR_RGB2BGR)\n",
    "    method = cv2.TM_CCOEFF_NORMED\n",
    "    res1 = cv2.matchTemplate(manual_crop_bgr, door_subsection_bgr, method)\n",
    "    res2 = cv2.matchTemplate(image_bgr, door_subsection_bgr, method)\n",
    "    \n",
    "    _, _, _, max_loc1 = cv2.minMaxLoc(res1)\n",
    "    _, _, _, max_loc2 = cv2.minMaxLoc(res2)\n",
    "    \n",
    "    shift_x = max_loc2[0] - max_loc1[0]\n",
    "    shift_y = max_loc2[1] - max_loc1[1]\n",
    "    \n",
    "    # Get dimensions\n",
    "    h1, w1 = ss.shape[:2]\n",
    "    h2, w2 = manual_crop.shape[:2]\n",
    "    \n",
    "    x1 = max(0, shift_x)\n",
    "    y1 = max(0, shift_y)\n",
    "    x2 = min(w1, w2 + shift_x)\n",
    "    y2 = min(h1, h2 + shift_y)\n",
    "    \n",
    "    cropped_overlap = ss[y1:y2, x1:x2]\n",
    "    return cropped_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f530021-59b9-41f7-ab77-67854d2f21c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94ae9b-b475-4c85-9f31-3dbfe5a869f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_groups = 1\n",
    "for group in range(num_groups):\n",
    "    manual_crop = Image.open(f\"data/manual_crop/{group}.png\")\n",
    "    # remove alpha channel added while cropping with ms paint\n",
    "    manual_crop = np.array(manual_crop)[:,:,0:3]\n",
    "\n",
    "    # Extract ground truth mask\n",
    "    truth_mask = get_mask(manual_crop)\n",
    "    np.savez_compressed(f\"data/mask/{group}.npz\", data=truth_mask)\n",
    "    \n",
    "    ss_dir = f\"data/screenshot/{group}\"\n",
    "    out_dir = f\"data/auto_crop/{group}\"\n",
    "    os.makedirs(out_dir)\n",
    "    for i, ss in enumerate(sorted(os.listdir(ss_dir))):\n",
    "        ss = np.array(Image.open(os.path.join(ss_dir, ss)))\n",
    "        crop = auto_crop_ss(ss, manual_crop)\n",
    "        #display(Image.fromarray(crop))\n",
    "        filename = os.path.join(out_dir, f\"{i}.npz\")\n",
    "        np.savez_compressed(filename, data=crop)\n",
    "        #filename = os.path.join(out_dir, f\"{i}.png\")\n",
    "        #Image.fromarray(crop).save(filename, format='PNG', compress_level=0)\n",
    "        if i % 10 == 0:\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a3496c-1f80-4dd3-9a2b-a676f719320d",
   "metadata": {},
   "source": [
    "# Generate 50% shrunk versions of auto_crop and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98b661-bf14-432a-b892-1d57d0777505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shrink_factor = 0.5\n",
    "num_groups = 4\n",
    "for group in range(num_groups):\n",
    "    manual_crop = Image.open(f\"data/manual_crop/{group}.png\")\n",
    "    # remove alpha channel added while cropping with ms paint\n",
    "    manual_crop = np.array(manual_crop)[:,:,0:3]\n",
    "    new_dim = int(shrink_factor * max(manual_crop.shape[0:2]))\n",
    "    shrunk_manual_crop = shrink_image(manual_crop, new_dim)\n",
    "\n",
    "    # Extract ground truth mask\n",
    "    truth_mask = get_mask(shrunk_manual_crop)\n",
    "    np.savez_compressed(f\"data/mask_50/{group}.npz\", data=truth_mask)\n",
    "    \n",
    "    ss_dir = f\"data/screenshot/{group}\"\n",
    "    out_dir = f\"data/auto_crop_50/{group}\"\n",
    "    #os.makedirs(out_dir)\n",
    "    for i, ss in enumerate(sorted(os.listdir(ss_dir))):\n",
    "        ss = np.array(Image.open(os.path.join(ss_dir, ss)))\n",
    "        crop = auto_crop_ss(ss, manual_crop)\n",
    "        new_dim = int(shrink_factor * max(crop.shape[0:2]))\n",
    "        shrunk_crop = shrink_image(crop, new_dim)\n",
    "        #display(Image.fromarray(crop))\n",
    "        filename = os.path.join(out_dir, f\"{i}.npz\")\n",
    "        np.savez_compressed(filename, data=shrunk_crop)\n",
    "        #filename = os.path.join(out_dir, f\"{i}.png\")\n",
    "        #Image.fromarray(crop).save(filename, format='PNG', compress_level=0)\n",
    "        if i % 10 == 0:\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90441612-013b-4fa0-9cdc-7ebc968f74ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe2058-3a61-4ec2-9ef1-cb47685e9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load(\"data/mask/0.npz\")['data']\n",
    "display(Image.fromarray(mask * 255, mode=\"L\"))\n",
    "\n",
    "crop = np.load(\"data/auto_crop/0/0.npz\")['data']\n",
    "display(Image.fromarray(crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fddd738-b550-4260-a642-63c0499d92c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load(\"data/mask_50/3.npz\")['data']\n",
    "display(Image.fromarray(mask * 255, mode=\"L\"))\n",
    "\n",
    "crop = np.load(\"data/auto_crop_50/3/3.npz\")['data']\n",
    "display(Image.fromarray(crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35439845-6d85-4803-820c-befaadadcb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d9386-3a0e-4bcc-afa5-525a844ae92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "door = extract_door_subsection(manual_crop)\n",
    "display(Image.fromarray(door))\n",
    "np.savez_compressed(\"data/door.npz\", data=door)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bbcc01-3e7f-4149-b20d-a5066c920126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4784da6-5d9f-47bd-b4de-d95009250d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_icon_mask(image, icon, original_mask, threshold=0.98):\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(image, icon, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    # Find all locations where the matching exceeds the threshold\n",
    "    locations = np.where(result >= threshold)\n",
    "    locations = list(zip(*locations[::-1]))  # Reverse to get (x, y)\n",
    "    \n",
    "    # Create a new mask for the icons\n",
    "    icon_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    h, w = icon.shape[:2]\n",
    "\n",
    "    ############### keep only left-most icon\n",
    "    ##### this is a hack based on coast layout\n",
    "    ##### doesn't work on upside down layout\n",
    "    locations = [min(locations, key=lambda x: x[0])]\n",
    "    \n",
    "    # Draw all icon locations on the mask\n",
    "    for loc in locations:\n",
    "        print(loc)\n",
    "        top_left = loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        icon_mask[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]] = 1\n",
    "    \n",
    "    # Create the new mask with two channels\n",
    "    new_mask = np.zeros((*original_mask.shape, 2), dtype=original_mask.dtype)\n",
    "    new_mask[:,:,0] = original_mask\n",
    "    new_mask[:,:,1] = icon_mask\n",
    "    \n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27ec00-bd1e-4cdf-b18c-4d27ab8523ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "door = np.load(\"data/door.npz\")['data']\n",
    "image = pad_to_square_multiple(np.array(Image.open(\"data/layout/raw/coast-0.png\"))[:,:,0:3], 64)\n",
    "original_mask = np.load(\"data/layout/extract/coast-0.npz\")['data']\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3aaa6f-90aa-468f-b6fa-38dc5f09b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = create_icon_mask(image, door, original_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df12db-47b0-4e00-bb0b-13864fa99d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d721c9-33ec-434c-aba0-e49aff04101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsdf = (asdf[:,:,0] + asdf[:,:,1]).reshape(asdf.shape[0:2])\n",
    "Image.fromarray(bsdf * 255, mode=\"L\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poemap",
   "language": "python",
   "name": "poemap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
