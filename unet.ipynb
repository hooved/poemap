{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4568c2-1b19-4038-a121-9273b86a4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from https://github.com/milesial/Pytorch-UNet\n",
    " and from https://github.com/tinygrad/tinygrad/examples/stable_diffusion.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994a7f9-78fc-488f-853e-57392a1f0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import Tensor\n",
    "from tinygrad.nn import Conv2d, ConvTranspose2d, BatchNorm2d\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837a9d3-b471-453b-b13b-cc92f03de798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleconv(in_chan, out_chan):\n",
    "    return [Conv2d(in_chan, out_chan, kernel_size=3, padding=1), BatchNorm2d(out_chan), Tensor.relu,\n",
    "        Conv2d(out_chan, out_chan, kernel_size=3, padding=1), BatchNorm2d(out_chan), Tensor.relu]\n",
    "\n",
    "class UNet:\n",
    "    def __init__(self):\n",
    "        self.save_intermediates = [\n",
    "            doubleconv(3, 64), \n",
    "            [Tensor.max_pool2d, *doubleconv(64, 128)],\n",
    "        ]\n",
    "        self.middle = [\n",
    "            Tensor.max_pool2d, *doubleconv(128, 256),\n",
    "            ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "        ]\n",
    "        self.consume_intermediates = [\n",
    "            [*doubleconv(256, 128), ConvTranspose2d(128, 64, kernel_size=2, stride=2)],\n",
    "            [*doubleconv(128, 64), Conv2d(64, 2, kernel_size=1)],\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        intermediates = []\n",
    "        for b in self.save_intermediates:\n",
    "            for bb in b:\n",
    "                x = bb(x)\n",
    "            intermediates.append(x)\n",
    "        for bb in self.middle:\n",
    "            x = bb(x)\n",
    "        for b in self.consume_intermediates:\n",
    "            x = intermediates.pop().cat(x, dim=1)\n",
    "            for bb in b:\n",
    "                x = bb(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5958f-05ce-4120-aaa3-e923fc5ea14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f28f7-4287-4b88-918e-67d9433bdf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82c5fa-7069-4b04-b8b4-3f094db5c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor.randn(1,3,100,100)\n",
    "y = unet(x)\n",
    "#assert x.shape == y.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a636b3-860d-42cb-b2c4-0cf415816933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64663adb-435b-491a-ba16-e27389c0ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, image_dir, mask_dir, patch_size=(64, 64), normalize=True, \n",
    "                 flip_prob=0.5, rotate_prob=0.5, noise_prob=0,):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.patch_size = patch_size\n",
    "        self.normalize = normalize\n",
    "        self.flip_prob = flip_prob\n",
    "        self.rotate_prob = rotate_prob\n",
    "        self.noise_prob = noise_prob\n",
    "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.npz'))])\n",
    "        self.mask_files = [f for f in os.listdir(image_dir) if f.endswith(('.npz'))]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        # Randomly distribute samples across images\n",
    "        shares = np.random.dirichlet(np.ones(len(self.image_files)), size=1)[0]\n",
    "        result = np.round(shares * batch_size).astype(int)\n",
    "        # Adjust to ensure sum is exactly batch_size\n",
    "        diff = batch_size - result.sum()\n",
    "        result[np.argmax(result)] += diff\n",
    "\n",
    "        image_patches, mask_patches = [], []\n",
    "        mask = np.load(os.path.join(self.mask_dir, self.mask_files[0]))['data']\n",
    "        for i, num_samples in enumerate(result):\n",
    "            image = np.load(os.path.join(self.image_dir, self.image_files[i]))['data']\n",
    "            image = self._normalize(image) if self.normalize else image\n",
    "            for _ in range(num_samples):\n",
    "                ip, mp = self._random_crop(image, mask)\n",
    "                ip, mp = self._apply_augmentations(ip, mp)\n",
    "                image_patches.append(ip)\n",
    "                mask_patches.append(mp)\n",
    "        return np.array(image_patches), np.array(mask_patches)\n",
    "\n",
    "    def _apply_augmentations(self, image, mask):\n",
    "        if random.random() < self.flip_prob:\n",
    "            image, mask = self._random_flip(image, mask)\n",
    "        if random.random() < self.rotate_prob:\n",
    "            image, mask = self._random_rotate(image, mask)\n",
    "        if random.random() < self.noise_prob:\n",
    "            image = self._random_noise(image)  # Apply noise only to the image, not the mask\n",
    "        return image, mask\n",
    "\n",
    "    def _random_crop(self, image, mask):\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.patch_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image_patch = image[top:top+new_h, left:left+new_w]\n",
    "        mask_patch = mask[top:top+new_h, left:left+new_w]\n",
    "\n",
    "        return image_patch, mask_patch\n",
    "\n",
    "    def _random_flip(self, image, mask):\n",
    "        return np.fliplr(image), np.fliplr(mask)\n",
    "\n",
    "    def _random_rotate(self, image, mask):\n",
    "        k = random.choice([1, 2, 3])  # 90, 180, or 270 degrees\n",
    "        return np.rot90(image, k), np.rot90(mask, k)\n",
    "\n",
    "    def _random_noise(self, image):\n",
    "        noise = np.random.normal(0, 0.05, image.shape)\n",
    "        return np.clip(image + noise, 0, 1)\n",
    "\n",
    "    def _normalize(self, image):\n",
    "        #return (image - np.mean(image)) / np.std(image)\n",
    "        normalized = np.zeros_like(image, dtype=np.float32)\n",
    "        for i in range(image.shape[2]):\n",
    "            channel = image[:,:,i]\n",
    "            mean = np.mean(channel)\n",
    "            std = np.std(channel)\n",
    "            normalized[:,:,i] = (channel - mean) / (std + 1e-8)  # adding small epsilon to avoid division by zero\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1daac-c577-417d-add3-b41ea5efb0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a3172-7267-44ac-b815-092d0eefec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    image_dir=\"data/auto_crop/0\",\n",
    "    mask_dir=\"data/mask\",\n",
    "    normalize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560eb3c-e5ed-44ba-896e-8dc9bd1a2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dl.get_batch(10)\n",
    "for a,b in zip(x,y):\n",
    "    if np.any(b > 0):\n",
    "        display(Image.fromarray(a))\n",
    "        display(Image.fromarray(b * 255, mode=\"L\"))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3eac4-00b1-43b4-a8c4-39238fe5c98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poemap",
   "language": "python",
   "name": "poemap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
